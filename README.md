# ğŸ›ï¸ E-Commerce Data Pipeline (Sprint Project 01)

### ğŸ“š Proyecto del Programa Anyone AI â€” Data Science & Machine Learning Track

Este proyecto tiene como objetivo construir un **pipeline de datos (ELT)** para analizar mÃ©tricas clave de un **E-commerce** real (Olist Store, Brasil) durante los aÃ±os **2016â€“2018**, enfocado principalmente en **Revenue** y **Delivery**.

---

## ğŸ§  DescripciÃ³n del problema

La empresa de E-commerce desea comprender mejor su rendimiento histÃ³rico en dos Ã¡reas principales:

1. **Revenue (Ingresos)**
   - CuÃ¡nto facturÃ³ por aÃ±o.
   - CuÃ¡les fueron las categorÃ­as mÃ¡s y menos populares.
   - CÃ³mo se distribuyÃ³ el ingreso por estado.

2. **Delivery (Entregas)**
   - CuÃ¡nto tiempo tarda en entregar un pedido segÃºn el mes.
   - CuÃ¡l es la diferencia entre la fecha estimada y la real de entrega.
   - CÃ³mo afectan los feriados nacionales al cumplimiento de entregas.

El objetivo es crear una **tuberÃ­a de datos automatizada** que permita obtener y actualizar estos reportes fÃ¡cilmente, integrando datos de mÃºltiples fuentes.

---

## ğŸ—‚ï¸ Fuentes de datos

### 1ï¸âƒ£ Dataset Olist (CSV)
Dataset pÃºblico de **Olist Store**, con mÃ¡s de **100.000 pedidos** realizados en Brasil (2016â€“2018).  
Incluye informaciÃ³n sobre clientes, pedidos, productos, precios, pagos, envÃ­os y reseÃ±as.

ğŸ“¦ **Estructura del dataset**  
- `olist_customers_dataset.csv`  
- `olist_orders_dataset.csv`  
- `olist_order_items_dataset.csv`  
- `olist_order_payments_dataset.csv`  
- `olist_order_reviews_dataset.csv`  
- `olist_products_dataset.csv`  
- `olist_sellers_dataset.csv`  
- `product_category_name_translation.csv`

ğŸ—ºï¸ Esquema de la base de datos disponible en:


### 2ï¸âƒ£ API de feriados pÃºblicos
Se utiliza la API [Nager.Date](https://date.nager.at) para obtener los **feriados nacionales de Brasil** y correlacionarlos con las demoras en las entregas.

---

## âš™ï¸ TecnologÃ­as utilizadas

| Herramienta | PropÃ³sito |
|--------------|-----------|
| ğŸ **Python** | Lenguaje principal |
| ğŸ§® **Pandas** | Limpieza y transformaciÃ³n de datos (Extract & Load) |
| ğŸŒ **Requests** | Consumo de la API pÃºblica de feriados |
| ğŸ—ƒï¸ **SQLite** | Almacenamiento y consultas en Data Warehouse |
| ğŸ’¾ **SQL** | TransformaciÃ³n y anÃ¡lisis de datos |
| ğŸ“Š **Matplotlib / Seaborn** | VisualizaciÃ³n de resultados |
| ğŸ““ **Jupyter Notebook** | Reporte interactivo |
| âš¡ **Black** | Formato de cÃ³digo automÃ¡tico |
| âœ… **Pytest** | Pruebas unitarias |

---

## ğŸ—ï¸ Estructura del proyecto

E-commerce-ELT-Pipeline/
â”‚
â”œâ”€â”€ data/ # CSVs del dataset Olist
â”œâ”€â”€ images/ # Diagramas y visualizaciones
â”œâ”€â”€ sql/ # Consultas SQL de transformaciÃ³n
â”‚ â”œâ”€â”€ revenue_by_month_year.sql
â”‚ â”œâ”€â”€ revenue_per_state.sql
â”‚ â”œâ”€â”€ delivery_date_difference.sql
â”‚ â””â”€â”€ ...
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ extract.py # ExtracciÃ³n de datos CSV
â”‚ â”œâ”€â”€ load.py # Carga a SQLite
â”‚ â””â”€â”€ transform.py # Consultas SQL + cÃ¡lculos
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ report.ipynb # Visualizaciones e insights
â”‚
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ test_transform.py # ValidaciÃ³n de queries
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ ASSIGNMENT.md
â”œâ”€â”€ README.md
â””â”€â”€ main.py # Script principal del pipeline


---

## ğŸš€ InstalaciÃ³n y ejecuciÃ³n

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/NicoGigenaVaras/E-commerce-ELT-Pipeline.git
   cd E-commerce-ELT-Pipeline

python -m venv venv
source venv/bin/activate       # macOS/Linux
venv\Scripts\activate          # Windows

pip install -r requirements.txt

python main.py

black --line-length=88 .

pytest tests/

ğŸ“ˆ Resultados esperados

Reportes anuales y mensuales de revenue.

Top 10 categorÃ­as mÃ¡s y menos rentables.

DistribuciÃ³n de ingresos por estado.

AnÃ¡lisis de tiempos de entrega vs fechas estimadas.

Impacto de feriados en demoras logÃ­sticas.

Las visualizaciones se generan en notebooks/report.ipynb e incluyen grÃ¡ficos de barras, series temporales y mapas de calor.

ğŸ§ª Testing

El proyecto incluye pruebas unitarias con Pytest para validar la consistencia de los datos y los resultados de las consultas SQL.

Ejemplo:

pytest tests/test_transform.py -v

Para mÃ¡s informaciÃ³n:

Effective Python Testing with Pytest

Hitchhikerâ€™s Guide to Python â€” Testing Your Code

ğŸ‘¨â€ğŸ’» Autor

NicolÃ¡s Eduardo Gigena Varas
ğŸ’¼ Software Developer @ Banco de CÃ³rdoba
ğŸ“ Data Science & Machine Learning Student @ Anyone AI
ğŸŒ GitHub
 | LinkedIn
 | ğŸ“§ nicogigenavaras@gmail.com

ğŸ“„ Licencia

Este proyecto fue desarrollado con fines educativos como parte del programa Anyone AI Bootcamp.
Puedes usarlo y modificarlo libremente citando la fuente original.
